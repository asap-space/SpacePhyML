{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SpacePhyML SpacePhyML is a framework for working with space physics datasets. It aims to bring togheter already existing datasets for ease of usage and enable the simple creation of new datasets in the future. It is built on the torch dataset class but can be used in Tensorflow. Checkout the Quick Start to get going. Automatics in Space Exploration (ASAP) The ASAP project is dedicated to designing and developing advanced algorithms that leverage artificial intelligence to automate onboard operations for space missions. These algorithms are specifically tailored for implementation on onboard processors, enhancing the efficiency, autonomy, and reliability of space systems. By integrating AI techniques, the project aims to reduce manual intervention, optimize mission performance, and enable smarter decision-making in real-time operational scenarios. Futher information can be found on the ASAP Project website, and the latest updates are posted on the project LinkedIn page: Website: asap-space.eu LinkedIn: linkedin.com/company/asap-space/ Youtube: youtube.com/@ASAP-space-eu ASAP has received funding from the European Union\u2019s HORIZON Research and Innovation Action under the Grant Agreement No 101082633. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union. Contributions","title":"Home"},{"location":"#welcome-to-spacephyml","text":"SpacePhyML is a framework for working with space physics datasets. It aims to bring togheter already existing datasets for ease of usage and enable the simple creation of new datasets in the future. It is built on the torch dataset class but can be used in Tensorflow. Checkout the Quick Start to get going.","title":"Welcome to SpacePhyML"},{"location":"#automatics-in-space-exploration-asap","text":"The ASAP project is dedicated to designing and developing advanced algorithms that leverage artificial intelligence to automate onboard operations for space missions. These algorithms are specifically tailored for implementation on onboard processors, enhancing the efficiency, autonomy, and reliability of space systems. By integrating AI techniques, the project aims to reduce manual intervention, optimize mission performance, and enable smarter decision-making in real-time operational scenarios. Futher information can be found on the ASAP Project website, and the latest updates are posted on the project LinkedIn page: Website: asap-space.eu LinkedIn: linkedin.com/company/asap-space/ Youtube: youtube.com/@ASAP-space-eu ASAP has received funding from the European Union\u2019s HORIZON Research and Innovation Action under the Grant Agreement No 101082633. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union.","title":"Automatics in Space Exploration (ASAP)"},{"location":"#contributions","text":"","title":"Contributions"},{"location":"quick_start/","text":"Quick Start Installation To use SpacePhyML you can install the package using pip. pip install git+https://github.com/Jonah-E/SpacePhyML.git Usage Create a dataset through the commandline tool using the dataset generator. spacephyml create my_dataset.csv Load the dataset in your python script, alternativly you can use one of the already exisiting datasets . from spacephyml.datasets.general.mms import ExternalMMSData dataset = ExternalMMSData('my_dataset.csv') Load a model and classify the data. from spacephyml.models.mms import PCReduced model = PCReduced('s42') labels = {'human': [], 'classifier': [], 'epoch': []} with torch.no_grad(): for x, l, e in DataLoader(dataset, batch_size=32): lc = model(x) lc = torch.argmax(lc, axis = 1) labels['human'].extend(l) labels['classifier'].extend(lc) labels['epoch'].extend(e)","title":"Quick Start"},{"location":"quick_start/#quick-start","text":"","title":"Quick Start"},{"location":"quick_start/#installation","text":"To use SpacePhyML you can install the package using pip. pip install git+https://github.com/Jonah-E/SpacePhyML.git","title":"Installation"},{"location":"quick_start/#usage","text":"Create a dataset through the commandline tool using the dataset generator. spacephyml create my_dataset.csv Load the dataset in your python script, alternativly you can use one of the already exisiting datasets . from spacephyml.datasets.general.mms import ExternalMMSData dataset = ExternalMMSData('my_dataset.csv') Load a model and classify the data. from spacephyml.models.mms import PCReduced model = PCReduced('s42') labels = {'human': [], 'classifier': [], 'epoch': []} with torch.no_grad(): for x, l, e in DataLoader(dataset, batch_size=32): lc = model(x) lc = torch.argmax(lc, axis = 1) labels['human'].extend(l) labels['classifier'].extend(lc) labels['epoch'].extend(e)","title":"Usage"},{"location":"reference/SUMMARY/","text":"datasets creator general mms pandas spedaswrapper mms models arcs mms mms transforms utils file_download mms","title":"SUMMARY"},{"location":"reference/transforms/","text":"Different useful transforms. Compose Compose ( * transforms ) Compose multiple transforms into one. Examples: >>> import spacephyml.transforms as tf >>> transforms = tf . Compose ( tf . Threshold ( 0 , 1 ), tf . Flatten ()) Parameters: Name Type Description Default transforms callables) All the transforms to compose. () IonDist_Transform IonDist_Transform ( norm = ( - 28 , - 17 )) Bases: Compose The default transform used in MMS1IonDistLabeled. Parameters: Name Type Description Default norm tuple The values to threshold and calculate LogNorm with. (-28, -17) ZScoreNorm ZScoreNorm ( mean , std ) Calculate the Z-Score norm using specified mean and std. Threshold Threshold ( thresholds ) Threshold the sample. LogNorm LogNorm ( normalization = None ) Log Normalize the data between a given range Flatten Filter for flattening the data Log10 Calculate the log10 of all non zero values in the sample. Roll Roll ( shift = 16 , axis =- 3 ) Perform a roll along a axis. MoveAxis MoveAxis ( src =- 1 , dst =- 3 ) Move around the axis in the sample. Sum Sum ( axis =- 1 ) Calculate the sum along specified axis. Mean Mean ( axis =- 1 ) Calculate the mean along specified axis.","title":"transforms"},{"location":"reference/transforms/#spacephyml.transforms.Compose","text":"Compose ( * transforms ) Compose multiple transforms into one. Examples: >>> import spacephyml.transforms as tf >>> transforms = tf . Compose ( tf . Threshold ( 0 , 1 ), tf . Flatten ()) Parameters: Name Type Description Default transforms callables) All the transforms to compose. ()","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;Compose"},{"location":"reference/transforms/#spacephyml.transforms.IonDist_Transform","text":"IonDist_Transform ( norm = ( - 28 , - 17 )) Bases: Compose The default transform used in MMS1IonDistLabeled. Parameters: Name Type Description Default norm tuple The values to threshold and calculate LogNorm with. (-28, -17)","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;IonDist_Transform"},{"location":"reference/transforms/#spacephyml.transforms.ZScoreNorm","text":"ZScoreNorm ( mean , std ) Calculate the Z-Score norm using specified mean and std.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ZScoreNorm"},{"location":"reference/transforms/#spacephyml.transforms.Threshold","text":"Threshold ( thresholds ) Threshold the sample.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;Threshold"},{"location":"reference/transforms/#spacephyml.transforms.LogNorm","text":"LogNorm ( normalization = None ) Log Normalize the data between a given range","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;LogNorm"},{"location":"reference/transforms/#spacephyml.transforms.Flatten","text":"Filter for flattening the data","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;Flatten"},{"location":"reference/transforms/#spacephyml.transforms.Log10","text":"Calculate the log10 of all non zero values in the sample.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;Log10"},{"location":"reference/transforms/#spacephyml.transforms.Roll","text":"Roll ( shift = 16 , axis =- 3 ) Perform a roll along a axis.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;Roll"},{"location":"reference/transforms/#spacephyml.transforms.MoveAxis","text":"MoveAxis ( src =- 1 , dst =- 3 ) Move around the axis in the sample.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;MoveAxis"},{"location":"reference/transforms/#spacephyml.transforms.Sum","text":"Sum ( axis =- 1 ) Calculate the sum along specified axis.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;Sum"},{"location":"reference/transforms/#spacephyml.transforms.Mean","text":"Mean ( axis =- 1 ) Calculate the mean along specified axis.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;Mean"},{"location":"reference/datasets/","text":"SpacePhyML Datasets","title":"Index"},{"location":"reference/datasets/creator/","text":"Script for creating dataset based on exisiting labels. get_dataset get_dataset ( label_source , trange , resample = None , clean = True , samples = 0 , var_list = [ 'mms1_dis_dist_fast' ]) Get a dataset based on a given config. Parameters: Name Type Description Default label_source string The source for the labels, either Olshevsky or Unlabeled. required trange List List with the start and end times for the dataset. The times should be strings and can have either the format YYYY-mm-DD or YYYY-mm-DD/HH:MM:SS required resample string The resample frequency, this varible follow the rules from the pandas resample function . Cannot be used with label_source set to Olshevsky. None clean Bool If unknown (-1) labels should be removed. True samples Integer The number of samples per label, set to 0 for all samples. 0 var_list List List of varibles to get from the CDF-files ['mms1_dis_dist_fast'] Returns: Type Description A pandas DataFrame with the created dataset. create_dataset create_dataset ( dataset_path , trange , force = False , ** kwargs ) Create a dataset file based on given config. Parameters: Name Type Description Default dataset_path string Path to store dataset, end with either .csv or .feather. required trange List List with the start and end times for the dataset. The times should be strings and can have either the format YYYY-mm-DD or YYYY-mm-DD/HH:MM:SS required force Bool Overwrite exisiting file if one exists. False **kwargs Futher arguments, passed directy to get_dataset(..) {}","title":"creator"},{"location":"reference/datasets/creator/#spacephyml.datasets.creator.get_dataset","text":"get_dataset ( label_source , trange , resample = None , clean = True , samples = 0 , var_list = [ 'mms1_dis_dist_fast' ]) Get a dataset based on a given config. Parameters: Name Type Description Default label_source string The source for the labels, either Olshevsky or Unlabeled. required trange List List with the start and end times for the dataset. The times should be strings and can have either the format YYYY-mm-DD or YYYY-mm-DD/HH:MM:SS required resample string The resample frequency, this varible follow the rules from the pandas resample function . Cannot be used with label_source set to Olshevsky. None clean Bool If unknown (-1) labels should be removed. True samples Integer The number of samples per label, set to 0 for all samples. 0 var_list List List of varibles to get from the CDF-files ['mms1_dis_dist_fast'] Returns: Type Description A pandas DataFrame with the created dataset.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;get_dataset"},{"location":"reference/datasets/creator/#spacephyml.datasets.creator.create_dataset","text":"create_dataset ( dataset_path , trange , force = False , ** kwargs ) Create a dataset file based on given config. Parameters: Name Type Description Default dataset_path string Path to store dataset, end with either .csv or .feather. required trange List List with the start and end times for the dataset. The times should be strings and can have either the format YYYY-mm-DD or YYYY-mm-DD/HH:MM:SS required force Bool Overwrite exisiting file if one exists. False **kwargs Futher arguments, passed directy to get_dataset(..) {}","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;create_dataset"},{"location":"reference/datasets/mms/","text":"Specific MMS Datasets. MMS1IonDistLabeled MMS1IonDistLabeled ( dataset , path = './datasets' , data_root = None , transform = None , cache = True , return_epoch = False ) Bases: ExternalMMSData This dataset contains two versions samled from labels created by Olshevsky, et. al. (2021)[^1]. The data samples in this dataset have one of the following labels: Value Label 0 Solar Wind (SW) 1 Ion foreshock (IF) 2 Magnetosheath (MSH) 3 Magnetosphere (MSP) There are 10,000 samples for each label, for a total of 40,000 samples in each version of the dataset. Examples: >>> from spacephyml.datasets.mms import MMS1IonDistLabeled >>> dataset = MMS1IonDistLabeled ( 'SCDec017' ) Olshevsky, V., et al. (2021). Automated classification of plasma regions using 3D particle energy distributions. Journal of Geophysical Research: Space Physics, https://doi.org/10.1029/2021JA029620 \u21a9 Parameters: Name Type Description Default dataset string The dataset, either SCNov2017 or SCDec2017. required path string The path for storing the dataset (not the actuall data). './datasets' data_root string The override the default root directory to for the MMS data storage. None transform callable Optional transform to be applied on each sample. None cache bool If data should be cached. True return_epoch bool If the label epoch should be returned. False","title":"mms"},{"location":"reference/datasets/mms/#spacephyml.datasets.mms.MMS1IonDistLabeled","text":"MMS1IonDistLabeled ( dataset , path = './datasets' , data_root = None , transform = None , cache = True , return_epoch = False ) Bases: ExternalMMSData This dataset contains two versions samled from labels created by Olshevsky, et. al. (2021)[^1]. The data samples in this dataset have one of the following labels: Value Label 0 Solar Wind (SW) 1 Ion foreshock (IF) 2 Magnetosheath (MSH) 3 Magnetosphere (MSP) There are 10,000 samples for each label, for a total of 40,000 samples in each version of the dataset. Examples: >>> from spacephyml.datasets.mms import MMS1IonDistLabeled >>> dataset = MMS1IonDistLabeled ( 'SCDec017' ) Olshevsky, V., et al. (2021). Automated classification of plasma regions using 3D particle energy distributions. Journal of Geophysical Research: Space Physics, https://doi.org/10.1029/2021JA029620 \u21a9 Parameters: Name Type Description Default dataset string The dataset, either SCNov2017 or SCDec2017. required path string The path for storing the dataset (not the actuall data). './datasets' data_root string The override the default root directory to for the MMS data storage. None transform callable Optional transform to be applied on each sample. None cache bool If data should be cached. True return_epoch bool If the label epoch should be returned. False","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;MMS1IonDistLabeled"},{"location":"reference/datasets/general/","text":"","title":"Index"},{"location":"reference/datasets/general/mms/","text":"Module containing different datasets. ExternalMMSData ExternalMMSData ( dataset_path , rootdir = None , transform = None , cache = True , return_epoch = True ) Bases: Dataset Loading a dataset with labeled MMS data based on dataset file. This dataset class looks for datafiles stored in CDF files in another location. By default SpacePhyML will look for external MMS data at the PySPEDAS data location ( PySPEDAS .) If the PySPEDAS environmental variable's are not set data will be placed at $HOME/spacephyml_data/mms , following the same directory structure as PySPEDAS (and the MMS Science Data Center ). Data files that are missing when the class is initialised will be downloaded. The dataset file have to have the following columns: label : The label corresponding to the sample epoch : The CDF epoch for the label file {i} : Specifying the MMS CDF file to read data from, the {i} is a running number. var_name {i} : The variable in the CDF file to read, the {i} is a running number. epoch {i} : The CDF epoch to read data from the {i} is a running number. Warning If loading data fail it may be due to the cdf file being corrupt. Delete the failing file and retry. Examples: >>> from spacephyml.datasets.general import ExternalMMSData >>> dataset = ExternalMMSData ( './mydataset.csv' ) Parameters: Name Type Description Default dataset_path string Path to the file containing the dataset. required rootdir string The override the default rootdir to for the MMS data storage. None transform callable Optional transform to be applied on each sample. None cache bool If data should be cached. True return_epoch bool If the label epoch should be returned. True","title":"mms"},{"location":"reference/datasets/general/mms/#spacephyml.datasets.general.mms.ExternalMMSData","text":"ExternalMMSData ( dataset_path , rootdir = None , transform = None , cache = True , return_epoch = True ) Bases: Dataset Loading a dataset with labeled MMS data based on dataset file. This dataset class looks for datafiles stored in CDF files in another location. By default SpacePhyML will look for external MMS data at the PySPEDAS data location ( PySPEDAS .) If the PySPEDAS environmental variable's are not set data will be placed at $HOME/spacephyml_data/mms , following the same directory structure as PySPEDAS (and the MMS Science Data Center ). Data files that are missing when the class is initialised will be downloaded. The dataset file have to have the following columns: label : The label corresponding to the sample epoch : The CDF epoch for the label file {i} : Specifying the MMS CDF file to read data from, the {i} is a running number. var_name {i} : The variable in the CDF file to read, the {i} is a running number. epoch {i} : The CDF epoch to read data from the {i} is a running number. Warning If loading data fail it may be due to the cdf file being corrupt. Delete the failing file and retry. Examples: >>> from spacephyml.datasets.general import ExternalMMSData >>> dataset = ExternalMMSData ( './mydataset.csv' ) Parameters: Name Type Description Default dataset_path string Path to the file containing the dataset. required rootdir string The override the default rootdir to for the MMS data storage. None transform callable Optional transform to be applied on each sample. None cache bool If data should be cached. True return_epoch bool If the label epoch should be returned. True","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;ExternalMMSData"},{"location":"reference/datasets/general/pandas/","text":"Module containing different datasets. PandasDataset PandasDataset ( dataset_path , transform = None , data_columns = None , label_column = None , return_index = True ) Bases: Dataset Loading a dataset contained within a .csv or .feather file. The dataset file have to have the following columns: label (optional): The label corresponding to the sample. {data column name}: Columns containing data to extract. Examples: >>> from spacephyml.datasets import PandasDataset >>> dataset = PandasDataset ( './mydataset.csv' ) Parameters: Name Type Description Default dataset_path string Path to the file containing the dataset. required transform callable Optional transform to be applied on each data sample. None data_columns list Which columns to use for data. None label_column string Which column to use for label. None Returns: Type Description Will return a list with with all the data varibles in a list followed by the label.","title":"pandas"},{"location":"reference/datasets/general/pandas/#spacephyml.datasets.general.pandas.PandasDataset","text":"PandasDataset ( dataset_path , transform = None , data_columns = None , label_column = None , return_index = True ) Bases: Dataset Loading a dataset contained within a .csv or .feather file. The dataset file have to have the following columns: label (optional): The label corresponding to the sample. {data column name}: Columns containing data to extract. Examples: >>> from spacephyml.datasets import PandasDataset >>> dataset = PandasDataset ( './mydataset.csv' ) Parameters: Name Type Description Default dataset_path string Path to the file containing the dataset. required transform callable Optional transform to be applied on each data sample. None data_columns list Which columns to use for data. None label_column string Which column to use for label. None Returns: Type Description Will return a list with with all the data varibles in a list followed by the label.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;PandasDataset"},{"location":"reference/datasets/general/spedaswrapper/","text":"SpedasWrapper SpedasWrapper ( tplot_vars , dropna = True , resample = None , transform = None ) Bases: Dataset Wrapper for loading varibles from pyspedas (tplot) into a pytorch dataset. The loading is a beast effort and might not work for some varibles and missions. The varibles are assumed to already be loaded into tplot in the correct timerange. Parameters: Name Type Description Default tplot_vars list of strings) The varibles to load. required dropna bool) Drop times where one of the varibles have value NAN. May result in removal of all data if tplot_vars are sampled at different times and resample is not set. True resample string) Time interval for resampling, follows the pandas style for resample. No resampling is done if set to None. None get_dataframe get_dataframe () Get the full pandas DataFrame Returns dataset : pandas DataFrame The full loaded data.","title":"spedaswrapper"},{"location":"reference/datasets/general/spedaswrapper/#spacephyml.datasets.general.spedaswrapper.SpedasWrapper","text":"SpedasWrapper ( tplot_vars , dropna = True , resample = None , transform = None ) Bases: Dataset Wrapper for loading varibles from pyspedas (tplot) into a pytorch dataset. The loading is a beast effort and might not work for some varibles and missions. The varibles are assumed to already be loaded into tplot in the correct timerange. Parameters: Name Type Description Default tplot_vars list of strings) The varibles to load. required dropna bool) Drop times where one of the varibles have value NAN. May result in removal of all data if tplot_vars are sampled at different times and resample is not set. True resample string) Time interval for resampling, follows the pandas style for resample. No resampling is done if set to None. None","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;SpedasWrapper"},{"location":"reference/datasets/general/spedaswrapper/#spacephyml.datasets.general.spedaswrapper.SpedasWrapper.get_dataframe","text":"get_dataframe () Get the full pandas DataFrame","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-method\"></code>&nbsp;get_dataframe"},{"location":"reference/datasets/general/spedaswrapper/#spacephyml.datasets.general.spedaswrapper.SpedasWrapper.get_dataframe--returns","text":"dataset : pandas DataFrame The full loaded data.","title":"Returns"},{"location":"reference/models/","text":"","title":"Index"},{"location":"reference/models/mms/","text":"PCBaseline PCBaseline ( model = 's42' , path = './models' ) Bases: PCBaseline_arc Load a train PCBaseline model for MMS dayside plasma region clessification. Examples: >>> from spacephyml.models.mms import PCBaseline >>> model = PCBaseline ( 's84' ) Parameters: Name Type Description Default model string The model to load, ['s42', 's84', 's168', 's336'] 's42' path string Path to loacation of stored model. './models' PCReduced PCReduced ( model = 's42' , path = './models' ) Bases: PCReduced_arc Load a train PCReduced model for MMS dayside plasma region clessification. Examples: >>> from spacephyml.models.mms import PCReduced >>> model = PCReduced ( 's84' ) Parameters: Name Type Description Default model string The model to load, ['s42', 's84', 's168', 's336'] 's42' path string Path to loacation of stored model. './models'","title":"mms"},{"location":"reference/models/mms/#spacephyml.models.mms.PCBaseline","text":"PCBaseline ( model = 's42' , path = './models' ) Bases: PCBaseline_arc Load a train PCBaseline model for MMS dayside plasma region clessification. Examples: >>> from spacephyml.models.mms import PCBaseline >>> model = PCBaseline ( 's84' ) Parameters: Name Type Description Default model string The model to load, ['s42', 's84', 's168', 's336'] 's42' path string Path to loacation of stored model. './models'","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;PCBaseline"},{"location":"reference/models/mms/#spacephyml.models.mms.PCReduced","text":"PCReduced ( model = 's42' , path = './models' ) Bases: PCReduced_arc Load a train PCReduced model for MMS dayside plasma region clessification. Examples: >>> from spacephyml.models.mms import PCReduced >>> model = PCReduced ( 's84' ) Parameters: Name Type Description Default model string The model to load, ['s42', 's84', 's168', 's336'] 's42' path string Path to loacation of stored model. './models'","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-class\"></code>&nbsp;PCReduced"},{"location":"reference/models/arcs/","text":"","title":"Index"},{"location":"reference/models/arcs/mms/","text":"","title":"mms"},{"location":"reference/utils/","text":"Common utils used by multiple scripts read_cdf_file read_cdf_file ( cdf_filepath , variables = None ) Read a cdf file, either fully or only a subset. Parameters: Name Type Description Default cdf_filepath string Path to the CDF file. required variables list List with tuples the names to store the varibles in and varibles to read. None Returns: Dictionary with the varibles. pandas_read_file pandas_read_file ( filepath ) Wrapper to handle reading data from multiple different file formats. Parameters: Name Type Description Default filepath string The file path including file extension. required Returns: A pandas DataFrame read from the given file path.","title":"Index"},{"location":"reference/utils/#spacephyml.utils.read_cdf_file","text":"read_cdf_file ( cdf_filepath , variables = None ) Read a cdf file, either fully or only a subset. Parameters: Name Type Description Default cdf_filepath string Path to the CDF file. required variables list List with tuples the names to store the varibles in and varibles to read. None Returns: Dictionary with the varibles.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;read_cdf_file"},{"location":"reference/utils/#spacephyml.utils.pandas_read_file","text":"pandas_read_file ( filepath ) Wrapper to handle reading data from multiple different file formats. Parameters: Name Type Description Default filepath string The file path including file extension. required Returns: A pandas DataFrame read from the given file path.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;pandas_read_file"},{"location":"reference/utils/file_download/","text":"Utils for file downloads. missing_files missing_files ( files , rootdir = '' ) Check for missing files. Parameters: Name Type Description Default files list The files (including path) to check. required rootdir string) A root path to add before the paths in the files list. '' Returns: Type Description A list of files (from the files argument) that does not exist. Will return 'None' if all files exists. download_file_with_status download_file_with_status ( url_file , filepath , session = None ) Download one file with a progress bar. Parameters: Name Type Description Default url_file string) The URL for downloading the file. required filepath string) The file path for storing the file required session The request session to use, if one exist. None","title":"file_download"},{"location":"reference/utils/file_download/#spacephyml.utils.file_download.missing_files","text":"missing_files ( files , rootdir = '' ) Check for missing files. Parameters: Name Type Description Default files list The files (including path) to check. required rootdir string) A root path to add before the paths in the files list. '' Returns: Type Description A list of files (from the files argument) that does not exist. Will return 'None' if all files exists.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;missing_files"},{"location":"reference/utils/file_download/#spacephyml.utils.file_download.download_file_with_status","text":"download_file_with_status ( url_file , filepath , session = None ) Download one file with a progress bar. Parameters: Name Type Description Default url_file string) The URL for downloading the file. required filepath string) The file path for storing the file required session The request session to use, if one exist. None","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;download_file_with_status"},{"location":"reference/utils/mms/","text":"Dataset utils specific to MMS. filename_to_filepath filename_to_filepath ( filename ) Create a filepath based on the filename for a mms CDF file Filename format is assumed to be mms1_fpi_fast_l2_dis-dist_20171129160000_v3.4.0.cdf {probe} {inst} {mode} {data_level} {data} {time} {version}.cdf Output will have the format: ./mms/mms1/fpi/fast/l2/dis-dist/2017/12/{filename} Parameters: Name Type Description Default filename string The filename to convert to a file path. required Returns: Type Description A string with the file path. get_file_list get_file_list ( start_date , end_date , data_rate = 'fast' , data_level = 'l2' , datatype = None , instrument = 'fpi' , sc_id = 'mms1' ) Get a list of files from the MMS Science Data center. For a full list of the possible parameters, look at \"Query Parameters\" on the MMS Science Data center, \"How to get data\" page: https://lasp.colorado.edu/mms/sdc/public/about/how-to/ Parameters: Name Type Description Default start_date string The start date for files, format YYYY-MM-DD. required end_date string The end date for files, format YYYY-MM-DD. required data_rate string The data rate, fast, burst or srvy. 'fast' data_level string The level of data post processing. 'l2' datatype string The datatype (not always used). None instrument string The instrument onboard mms. 'fpi' sc_id string The spacecraft id, mms1, mms2, mms3 or mms4. 'mms1' Returns: Type Description A list of files. download_cdf_files download_cdf_files ( rootdir , cdf_filepaths , session = None ) Download CDF files from the MMS Science Data Center based on a file list. Parameters: Name Type Description Default rootdir string Root directory for storing downloaded files. required cdf_filepaths list The paths to store the files (including filename). The filename have to be the same as the file to download. required session Object The request session to use, if one exists. None","title":"mms"},{"location":"reference/utils/mms/#spacephyml.utils.mms.filename_to_filepath","text":"filename_to_filepath ( filename ) Create a filepath based on the filename for a mms CDF file Filename format is assumed to be mms1_fpi_fast_l2_dis-dist_20171129160000_v3.4.0.cdf {probe} {inst} {mode} {data_level} {data} {time} {version}.cdf Output will have the format: ./mms/mms1/fpi/fast/l2/dis-dist/2017/12/{filename} Parameters: Name Type Description Default filename string The filename to convert to a file path. required Returns: Type Description A string with the file path.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;filename_to_filepath"},{"location":"reference/utils/mms/#spacephyml.utils.mms.get_file_list","text":"get_file_list ( start_date , end_date , data_rate = 'fast' , data_level = 'l2' , datatype = None , instrument = 'fpi' , sc_id = 'mms1' ) Get a list of files from the MMS Science Data center. For a full list of the possible parameters, look at \"Query Parameters\" on the MMS Science Data center, \"How to get data\" page: https://lasp.colorado.edu/mms/sdc/public/about/how-to/ Parameters: Name Type Description Default start_date string The start date for files, format YYYY-MM-DD. required end_date string The end date for files, format YYYY-MM-DD. required data_rate string The data rate, fast, burst or srvy. 'fast' data_level string The level of data post processing. 'l2' datatype string The datatype (not always used). None instrument string The instrument onboard mms. 'fpi' sc_id string The spacecraft id, mms1, mms2, mms3 or mms4. 'mms1' Returns: Type Description A list of files.","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;get_file_list"},{"location":"reference/utils/mms/#spacephyml.utils.mms.download_cdf_files","text":"download_cdf_files ( rootdir , cdf_filepaths , session = None ) Download CDF files from the MMS Science Data Center based on a file list. Parameters: Name Type Description Default rootdir string Root directory for storing downloaded files. required cdf_filepaths list The paths to store the files (including filename). The filename have to be the same as the file to download. required session Object The request session to use, if one exists. None","title":"<code class=\"doc-symbol doc-symbol-toc doc-symbol-function\"></code>&nbsp;download_cdf_files"},{"location":"user_guide/dataset_creator/","text":"Dataset Creator The dataset creator enables the creation of new datasets based on existing data and label sources. The data set creator can be used either with the command line interface (CLI) described below or in an python script using the API described here . CLI The CLI for the dataset creator can be accessed using with the command spacephyml create [-h] [--label_source {Olshevsky,Unlabeled}] [--start START] [--end END] [--force] [--clean] [--samples SAMPLES] [--resample RESAMPLE] [--var {...}] output The only required argument is the path to the output file ( output ). The output file can be either in CSV or Feather format and is determined by the file extension of the given output file. By default, a new dataset will not be created if the output file exists. This can be forced by setting the flag --force . Currently the creator supports creating datasets based of labels from Olshevsky or creating an unlabeled dataset. Creating a dataset based on the Olshevsky labels currently does not support resampling and can only be done using data from the FPI instrument on MMS1, see the variable list below The --start and --end flag gives the time range for creating the dataset. When creating a labeled data set, you have the option of creating a clean data set without and unknown labels. This done by setting the --clean flag. You can also select how many samples of each label you want by setting the --samples flag. When creating an unlabeled dataset, the dataset can be resampled to a sampling frequency specified by the --resample flag. This flag follow the rules from the pandas resample function . Supported variables Controlled by the --var flag. Varible Instrument mms1_dis_dist_fast FPI mms1_dis_energyspectr_omni_fast FPI mms1_dis_bulkv_gse_fast FPI mms1_dis_numberdensity_fast FPI mms1_dis_temppara_fast FPI mms1_dis_tempperp FPI Loading the dataset Once created the dataset can be loaded using one of the general loaders. Mission Resampled Dataset Class MMS Yes PandasDataset MMS No ExternalMMSData Olshevsky labels These labels are from the work of Olshevsky, et al. 1 who labeled data from the MMS1 spacecraft for November and December 2017. The labeled data is from the Earth's dayside and is labeled as one of the regions in the table below. Label Region -1 Undefined/Unknown 0 Solar Wind (SW) 1 Ion foreshock (IF) 2 Magnetosheath (MSH) 3 Magnetosphere (MSP) Olshevsky, V., et al. (2021). Automated classification of plasma regions using 3D particle energy distributions. Journal of Geophysical Research: Space Physics, https://doi.org/10.1029/2021JA029620 \u21a9","title":"Dataset Creator"},{"location":"user_guide/dataset_creator/#dataset-creator","text":"The dataset creator enables the creation of new datasets based on existing data and label sources. The data set creator can be used either with the command line interface (CLI) described below or in an python script using the API described here .","title":"Dataset Creator"},{"location":"user_guide/dataset_creator/#cli","text":"The CLI for the dataset creator can be accessed using with the command spacephyml create [-h] [--label_source {Olshevsky,Unlabeled}] [--start START] [--end END] [--force] [--clean] [--samples SAMPLES] [--resample RESAMPLE] [--var {...}] output The only required argument is the path to the output file ( output ). The output file can be either in CSV or Feather format and is determined by the file extension of the given output file. By default, a new dataset will not be created if the output file exists. This can be forced by setting the flag --force . Currently the creator supports creating datasets based of labels from Olshevsky or creating an unlabeled dataset. Creating a dataset based on the Olshevsky labels currently does not support resampling and can only be done using data from the FPI instrument on MMS1, see the variable list below The --start and --end flag gives the time range for creating the dataset. When creating a labeled data set, you have the option of creating a clean data set without and unknown labels. This done by setting the --clean flag. You can also select how many samples of each label you want by setting the --samples flag. When creating an unlabeled dataset, the dataset can be resampled to a sampling frequency specified by the --resample flag. This flag follow the rules from the pandas resample function .","title":"CLI"},{"location":"user_guide/dataset_creator/#supported-variables","text":"Controlled by the --var flag. Varible Instrument mms1_dis_dist_fast FPI mms1_dis_energyspectr_omni_fast FPI mms1_dis_bulkv_gse_fast FPI mms1_dis_numberdensity_fast FPI mms1_dis_temppara_fast FPI mms1_dis_tempperp FPI","title":"Supported variables"},{"location":"user_guide/dataset_creator/#loading-the-dataset","text":"Once created the dataset can be loaded using one of the general loaders. Mission Resampled Dataset Class MMS Yes PandasDataset MMS No ExternalMMSData","title":"Loading the dataset"},{"location":"user_guide/dataset_creator/#olshevsky-labels","text":"These labels are from the work of Olshevsky, et al. 1 who labeled data from the MMS1 spacecraft for November and December 2017. The labeled data is from the Earth's dayside and is labeled as one of the regions in the table below. Label Region -1 Undefined/Unknown 0 Solar Wind (SW) 1 Ion foreshock (IF) 2 Magnetosheath (MSH) 3 Magnetosphere (MSP) Olshevsky, V., et al. (2021). Automated classification of plasma regions using 3D particle energy distributions. Journal of Geophysical Research: Space Physics, https://doi.org/10.1029/2021JA029620 \u21a9","title":"Olshevsky labels"},{"location":"user_guide/datasets_general/","text":"Dataloaders spacephyml.datasets.general.mms","title":"Dataloaders"},{"location":"user_guide/datasets_general/#dataloaders","text":"","title":"Dataloaders"},{"location":"user_guide/datasets_general/#spacephymldatasetsgeneralmms","text":"","title":"spacephyml.datasets.general.mms"},{"location":"user_guide/datasets_mms/","text":"Datasets MMS1IonDistLabeled This dataset contains two versions samled from labels created by Olshevsky, et. al. (2021)[^1]. The data samples in this dataset have one of the following labels: Value Label 0 Solar Wind (SW) 1 Ion foreshock (IF) 2 Magnetosheath (MSH) 3 Magnetosphere (MSP) There are 10,000 samples for each label, for a total of 40,000 samples in each version of the dataset. Examples: >>> from spacephyml.datasets.mms import MMS1IonDistLabeled >>> dataset = MMS1IonDistLabeled ( 'SCDec017' ) Olshevsky, V., et al. (2021). Automated classification of plasma regions using 3D particle energy distributions. Journal of Geophysical Research: Space Physics, https://doi.org/10.1029/2021JA029620 \u21a9","title":"MMS"},{"location":"user_guide/datasets_mms/#datasets","text":"","title":"Datasets"},{"location":"user_guide/datasets_mms/#mms1iondistlabeled","text":"This dataset contains two versions samled from labels created by Olshevsky, et. al. (2021)[^1]. The data samples in this dataset have one of the following labels: Value Label 0 Solar Wind (SW) 1 Ion foreshock (IF) 2 Magnetosheath (MSH) 3 Magnetosphere (MSP) There are 10,000 samples for each label, for a total of 40,000 samples in each version of the dataset. Examples: >>> from spacephyml.datasets.mms import MMS1IonDistLabeled >>> dataset = MMS1IonDistLabeled ( 'SCDec017' ) Olshevsky, V., et al. (2021). Automated classification of plasma regions using 3D particle energy distributions. Journal of Geophysical Research: Space Physics, https://doi.org/10.1029/2021JA029620 \u21a9","title":"MMS1IonDistLabeled"},{"location":"user_guide/examples/","text":"Examples 01_create_new_dataset.py Creates a new dataset of MMS plasma distribution data using Olshevsky labels. from spacephyml.datasets.creator import create_dataset create_dataset('./mms_region.csv', trange=['2017-12-04/05:00:00','2017-12-04/15:00:00'], clean=False, label_source='Olshevsky', var_list=['mms1_dis_dist_fast']) 02_load_existing_dataset.py Load an existing dataset and model, then classify the data using the model. import torch from torch.utils.data import DataLoader from spacephyml.datasets.mms import MMS1IonDistLabeled from spacephyml.models.mms import PCReduced device = ( \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\" ) dataset = MMS1IonDistLabeled('SCNov2017') model = PCReduced('s42').to(device) labels = {'human': [], 'classifier': []} correct = 0 with torch.no_grad(): for x,l in DataLoader(dataset, batch_size=32): lc = model(x.to(device)).to('cpu') lc = torch.argmax(lc, axis = 1) correct += torch.sum(lc==l) labels['human'].extend(l) labels['classifier'].extend(lc) print(f'Accuracy: {correct/len(labels['human'])}') 03_classify_mms_region.py Classifying MMS dayside space plasma regions import torch from torch.utils.data import DataLoader from spacephyml.datasets.general.mms import ExternalMMSData from spacephyml.models.mms import PCReduced from spacephyml.datasets.creator import create_dataset from spacephyml.transforms import MMS1IonDistLabeled_Transform device = ( \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\" ) create_dataset('./mms_region.csv', trange=['2017-12-04/05:00:00','2017-12-04/15:00:00'], clean=False, label_source='Olshevsky', var_list=['mms1_dis_dist_fast']) dataset = ExternalMMSData('./mms_region.csv', transform = MMS1IonDistLabeled_Transform()) model = PCReduced('s42').to(device) labels = {'human': [], 'classifier': [], 'epoch': []} for x, l, epoch in DataLoader(dataset, batch_size=32): lc = model(x.to(device)).to('cpu') labels['human'].extend(l) labels['classifier'].extend(lc) labels['epoch'].extend(epoch) 04_train_new_models.py Train a new PCReduced model using the PCNov2017 dataset. import torch from torch import nn, optim from torch.utils.data import DataLoader from spacephyml.datasets.mms import MMS1IonDistLabeled from spacephyml.models.arcs.mms import PCReduced_arc, PCBaseline_arc _VERBOSE = True _EPOCHS = 5 _LEARNING_RATE = 1e-5 _BATCH_SIZE = 32 def train_loop(dataloader, model, loss_fn, optimizer, batch_size, device): model.train() size = len(dataloader.dataset) for batch, (x, y) in enumerate(dataloader): # Compute prediction and loss pred = model(x.to(device)) loss = loss_fn(pred, y.to(device)) # Backpropagation loss.backward() optimizer.step() optimizer.zero_grad() if _VERBOSE and batch % 100 == 0: loss, current = loss.item(), batch * batch_size + len(x) print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\") def train_model(model, dataset, batch_size = _BATCH_SIZE, device=\"cpu\"): dataloader_train = DataLoader(dataset, batch_size = _BATCH_SIZE, shuffle=True) model = model.to(device) loss_fn = nn.CrossEntropyLoss() optimizer = optim.Adam(model.parameters(), lr = _LEARNING_RATE) for t in range(_EPOCHS): print(f\"Epoch {t+1}\\n-------------------------------\") train_loop(dataloader_train, model, loss_fn, optimizer, batch_size, device) print(\"Done!\") return model def main(seed): device = ( \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\" ) torch.manual_seed(seed) print(f\"Using {device} device\") dataset = MMS1IonDistLabeled('SCNov2017') model = PCBaseline_arc() model = train_model(model, dataset, device = device) torch.save(model.classifier.state_dict(), f\"./model_PCBaseline_s{seed}.ptk\") if __name__ == \"__main__\": seed = 42 main(seed)","title":"Examples"},{"location":"user_guide/examples/#examples","text":"","title":"Examples"},{"location":"user_guide/examples/#01_create_new_datasetpy","text":"Creates a new dataset of MMS plasma distribution data using Olshevsky labels. from spacephyml.datasets.creator import create_dataset create_dataset('./mms_region.csv', trange=['2017-12-04/05:00:00','2017-12-04/15:00:00'], clean=False, label_source='Olshevsky', var_list=['mms1_dis_dist_fast'])","title":"01_create_new_dataset.py"},{"location":"user_guide/examples/#02_load_existing_datasetpy","text":"Load an existing dataset and model, then classify the data using the model. import torch from torch.utils.data import DataLoader from spacephyml.datasets.mms import MMS1IonDistLabeled from spacephyml.models.mms import PCReduced device = ( \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\" ) dataset = MMS1IonDistLabeled('SCNov2017') model = PCReduced('s42').to(device) labels = {'human': [], 'classifier': []} correct = 0 with torch.no_grad(): for x,l in DataLoader(dataset, batch_size=32): lc = model(x.to(device)).to('cpu') lc = torch.argmax(lc, axis = 1) correct += torch.sum(lc==l) labels['human'].extend(l) labels['classifier'].extend(lc) print(f'Accuracy: {correct/len(labels['human'])}')","title":"02_load_existing_dataset.py"},{"location":"user_guide/examples/#03_classify_mms_regionpy","text":"Classifying MMS dayside space plasma regions import torch from torch.utils.data import DataLoader from spacephyml.datasets.general.mms import ExternalMMSData from spacephyml.models.mms import PCReduced from spacephyml.datasets.creator import create_dataset from spacephyml.transforms import MMS1IonDistLabeled_Transform device = ( \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\" ) create_dataset('./mms_region.csv', trange=['2017-12-04/05:00:00','2017-12-04/15:00:00'], clean=False, label_source='Olshevsky', var_list=['mms1_dis_dist_fast']) dataset = ExternalMMSData('./mms_region.csv', transform = MMS1IonDistLabeled_Transform()) model = PCReduced('s42').to(device) labels = {'human': [], 'classifier': [], 'epoch': []} for x, l, epoch in DataLoader(dataset, batch_size=32): lc = model(x.to(device)).to('cpu') labels['human'].extend(l) labels['classifier'].extend(lc) labels['epoch'].extend(epoch)","title":"03_classify_mms_region.py"},{"location":"user_guide/examples/#04_train_new_modelspy","text":"Train a new PCReduced model using the PCNov2017 dataset. import torch from torch import nn, optim from torch.utils.data import DataLoader from spacephyml.datasets.mms import MMS1IonDistLabeled from spacephyml.models.arcs.mms import PCReduced_arc, PCBaseline_arc _VERBOSE = True _EPOCHS = 5 _LEARNING_RATE = 1e-5 _BATCH_SIZE = 32 def train_loop(dataloader, model, loss_fn, optimizer, batch_size, device): model.train() size = len(dataloader.dataset) for batch, (x, y) in enumerate(dataloader): # Compute prediction and loss pred = model(x.to(device)) loss = loss_fn(pred, y.to(device)) # Backpropagation loss.backward() optimizer.step() optimizer.zero_grad() if _VERBOSE and batch % 100 == 0: loss, current = loss.item(), batch * batch_size + len(x) print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\") def train_model(model, dataset, batch_size = _BATCH_SIZE, device=\"cpu\"): dataloader_train = DataLoader(dataset, batch_size = _BATCH_SIZE, shuffle=True) model = model.to(device) loss_fn = nn.CrossEntropyLoss() optimizer = optim.Adam(model.parameters(), lr = _LEARNING_RATE) for t in range(_EPOCHS): print(f\"Epoch {t+1}\\n-------------------------------\") train_loop(dataloader_train, model, loss_fn, optimizer, batch_size, device) print(\"Done!\") return model def main(seed): device = ( \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\" ) torch.manual_seed(seed) print(f\"Using {device} device\") dataset = MMS1IonDistLabeled('SCNov2017') model = PCBaseline_arc() model = train_model(model, dataset, device = device) torch.save(model.classifier.state_dict(), f\"./model_PCBaseline_s{seed}.ptk\") if __name__ == \"__main__\": seed = 42 main(seed)","title":"04_train_new_models.py"},{"location":"user_guide/overview/","text":"Overview Figure: Overview of the SpacePhyML framework.","title":"Overview"},{"location":"user_guide/overview/#overview","text":"Figure: Overview of the SpacePhyML framework.","title":"Overview"}]}